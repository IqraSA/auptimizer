

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>How to use Converter &mdash; Auptimizer  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="dlconvert_example.html" />
    <link rel="prev" title="Converter" href="dlconvert.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/AuptimizerWhiteLong.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="README.html">Auptimizer Quickstart</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Install and Setup <strong>Auptimizer</strong></a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hpo.html">Hyperparameter Optimization</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="edge.html">Edge Deployment Tools</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="profiler.html">Profiler</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="dlconvert.html">Converter</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">How to use Converter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install">Install</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parameters">Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#known-issues">Known Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="dlconvert_example.html">Examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="developer.html">For Developers</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="aup.html"><strong>Auptimizer</strong> APIs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Auptimizer</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="edge.html">Edge Deployment Tools</a> &raquo;</li>
        
          <li><a href="dlconvert.html">Converter</a> &raquo;</li>
        
      <li>How to use Converter</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/dlconvert_readme.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="how-to-use-converter">
<h1>How to use Converter<a class="headerlink" href="#how-to-use-converter" title="Permalink to this headline">¶</a></h1>
<p><strong>Converter</strong> is a format conversion tool for machine learning models. It encapsulates best practices of individual Machine Learning model conversions under a single API.</p>
<p>Converter allows you to:</p>
<ol class="arabic simple">
<li><p><strong>Make your models edge device-friendly.</strong> Transform models in Checkpoint (.meta), Keras (.h5/.hdf5), SavedModel (directory name), Protobuf (.pb), and Pytorch (.pt) into edge-optimized ONNX (.onnx) and TensorFlow Lite (.tflite) formats.</p></li>
<li><p><strong>Enhance model interoperability through standardization.</strong> Boost model compatibility with countless compilers, inference engines, and SoCs by converting it into the industry-standard ONNX format.</p></li>
<li><p><strong>Get a smaller and faster model.</strong> Make your model more compact and efficient by leveraging <a class="reference internal" href="#quantization">Quantization</a> built into the TensorFlow Lite converter.</p></li>
</ol>
<p>The following source model formats (and file extensions) can be converted to <strong>TensorFlow Lite (.tflite)</strong> and <strong>ONNX (.onnx)</strong>:</p>
<ul class="simple">
<li><p><strong>Checkpoint (.meta)</strong></p></li>
<li><p><strong>Keras (.h5/.hdf5)</strong></p></li>
<li><p><strong>SavedModel (directory name)</strong></p></li>
<li><p><strong>Protobuf (.pb)</strong></p></li>
<li><p><strong>PyTorch (.pt)</strong></p></li>
</ul>
<p>Additionally, Converter supports conversions:</p>
<ul class="simple">
<li><p>from Checkpoint to Protobuf</p></li>
<li><p>from Keras to Protobuf</p></li>
<li><p>from PyTorch to Keras</p></li>
</ul>
<p>TensorFlow 1.15, 2.1 - 2.3 and PyTorch 1.6.0 are tested. The conversion from SavedModel to TensorFlow Lite/ONNX requires TensorFlow version 2.x. Other conversions can be run using both TensorFlow 1.15 or 2.x.</p>
<div class="section" id="install">
<h2>Install<a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h2>
<p><em>Note:</em> Converter leverages conversion libraries that have different version requirements (mainly for TensorFlow).
It is highly recommended to use Docker or Python’s virtualenv to isolate your environment.</p>
<ol class="arabic">
<li><p>Install Auptimizer</p></li>
<li><p>Install additional libraries for using Converter:</p>
<p>If you would like to convert from Checkpoint/Keras/Protobuf/SavedModel model formats, please run: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">keras2onnx</span> <span class="pre">tf2onnx</span></code>. If you would like to convert from PyTorch format, please run:<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">pytorch2keras</span> <span class="pre">keras2onnx</span> <span class="pre">tf2onnx</span></code></p>
</li>
</ol>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p><strong>Recommended:</strong> Check whether your model architecture is supported for the target conversion <a class="reference external" href="https://github.com/LGE-ARC-AdvancedAI/auptimizer/tree/master/Examples/converter_examples/Tested_Models">here</a>.</p></li>
<li><p><strong>Important:</strong> Ensure that you can load and run your model, otherwise you will not be able to convert it successfully.</p></li>
<li><p>Specify conversion parameters. There are certain parameters to specify for each type of conversion. These parameters need to be written in a configuration <em>.json</em> file. You can list configurations for multiple model conversion tasks in a single .json file to execute model conversions sequentially.</p>
<p>An example configuration for converting a VGG16 Keras model to ONNX is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;convert_from&quot;</span><span class="p">:</span><span class="s2">&quot;test_models/VGG16.h5&quot;</span><span class="p">,</span>
    <span class="s2">&quot;convert_to&quot;</span><span class="p">:</span><span class="s2">&quot;converted_models/VGG16_keras.onnx&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>After preparing the configuration .json file, run the following command to start the conversions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">aup</span><span class="o">.</span><span class="n">dlconvert</span> <span class="o">-</span><span class="n">f</span> <span class="o">&lt;</span><span class="n">configuration</span> <span class="n">json</span> <span class="n">file</span><span class="o">&gt;</span>
</pre></div>
</div>
</li>
</ol>
<blockquote>
<div><p>Alternatively, you can also write the configuration in a <em>json dictionary</em> format, and run</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">aup</span><span class="o">.</span><span class="n">dlconvert</span> <span class="o">-</span><span class="n">d</span> <span class="o">&lt;</span><span class="n">configuration</span> <span class="n">json</span> <span class="n">dictionary</span><span class="o">&gt;</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h2>
<p>For <strong>all</strong> conversions, the two required parameters are <strong>convert_from</strong> and <strong>convert_to</strong>.</p>
<p>For each specific conversion, there can be additional parameters needed. These parameters are usually dependent on the source- and target model formats, and are summarized in the following chart:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 8%" />
<col style="width: 11%" />
<col style="width: 10%" />
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 12%" />
<col style="width: 9%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><div class="line-block">
<div class="line">From</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">To</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">quantization</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">input_nodes</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">output_nodes</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">network_script</div>
<div class="line">network_name</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">input_shape</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">onnx_opset</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">frozen</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">savedmodel_tag</div>
<div class="line">savedmodel_signature</div>
</div>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Keras</p></td>
<td><p>TensorFlow Lite</p></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>SavedModel</p></td>
<td><p>TensorFlow Lite</p></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Checkpoint</p></td>
<td><p>TensorFlow Lite</p></td>
<td><p>Optional</p></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Protobuf</p></td>
<td><p>TensorFlow Lite</p></td>
<td><p>Optional</p></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>PyTorch</p></td>
<td><p>TensorFlow Lite</p></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Keras</p></td>
<td><p>ONNX</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>SavedModel</p></td>
<td><p>ONNX</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><p>Optional</p></td>
<td></td>
<td><p>Optional</p></td>
</tr>
<tr class="row-odd"><td><p>Checkpoint</p></td>
<td><p>ONNX</p></td>
<td></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td></td>
<td><p>Optional</p></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Protobuf</p></td>
<td><p>ONNX</p></td>
<td></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td></td>
<td><p>Optional</p></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>PyTorch</p></td>
<td><p>ONNX</p></td>
<td></td>
<td></td>
<td></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td><p>Optional</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Keras</p></td>
<td><p>Protobuf</p></td>
<td></td>
<td></td>
<td><p>Required</p></td>
<td></td>
<td></td>
<td></td>
<td><p>Optional</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Checkpoint</p></td>
<td><p>Protobuf</p></td>
<td></td>
<td></td>
<td><p>Required</p></td>
<td></td>
<td></td>
<td></td>
<td><p>Optional</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>PyTorch</p></td>
<td><p>Keras</p></td>
<td></td>
<td></td>
<td></td>
<td><p>Required</p></td>
<td><p>Required</p></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><code class="docutils literal notranslate"><span class="pre">convert_from</span></code>
Required for <strong>all</strong> conversions. Input model file with one of the supported extensions: <cite>.meta</cite>, <cite>.h5/.hdf5</cite>, <cite>.pb</cite>, <cite>.pt</cite>, or a directory path for SavedModel.</p>
<p><code class="docutils literal notranslate"><span class="pre">convert_to</span></code>
Required for <strong>all</strong> conversions. Output model name with one of the supported extensions: <cite>.tflite</cite>, <cite>.onnx</cite>, <cite>.pb</cite>, or <cite>.h5/.hdf5</cite>.</p>
<p id="quantization"><code class="docutils literal notranslate"><span class="pre">quantization</span></code>
Parameter <em>quantization</em> includes a group of parameters used for enabling quantization while converting to TensorFlow Lite format. Post-training quantization is a built-in functionality of the TensorFlow Lite Converter. The Converter API supports calling this functionality.</p>
<p>To specify quantization parameters, write in the configuration .json file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
     <span class="s2">&quot;convert_from&quot;</span><span class="p">:</span><span class="s2">&quot;test_models/VGG16.h5&quot;</span><span class="p">,</span>
     <span class="s2">&quot;convert_to&quot;</span><span class="p">:</span><span class="s2">&quot;converted_models/VGG16_keras.tflite&quot;</span><span class="p">,</span>
     <span class="s2">&quot;quantization&quot;</span><span class="p">:</span> <span class="p">{</span>
         <span class="s2">&quot;optimization&quot;</span><span class="p">:</span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
         <span class="s2">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;float16&quot;</span><span class="p">,</span>
         <span class="s2">&quot;opsset&quot;</span><span class="p">:</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span>
         <span class="s2">&quot;load&quot;</span><span class="p">:</span><span class="s2">&quot;repdata.py&quot;</span>
     <span class="p">}</span>
 <span class="p">}</span>
</pre></div>
</div>
<p>More detail on post-training quantization capabilities and parameter setting can be found in <a class="reference external" href="https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_to_a_tensorflow_lite_model">Post-training quantization</a></p>
<p><code class="docutils literal notranslate"><span class="pre">optimization</span></code>
Enable/disable quantization for conversion. Choose from <cite>none</cite> or <cite>default</cite>. Default is <cite>none</cite>. When using <cite>none</cite>, no quantization will be performed and the converted TensorFlow Lite model will be in float32 format. When using <cite>default</cite>, best practices will be applied for quantization with the other given information via <cite>–type</cite>, <cite>–opsset</cite>, and <cite>–load</cite>.</p>
<p><code class="docutils literal notranslate"><span class="pre">type</span></code>
Target data type for constant values of the converted TensorFlow Lite model. Choose from <cite>float32</cite>, <cite>float16</cite>, <cite>int8</cite>,and <cite>uint8</cite>. Default is <cite>float32</cite>.</p>
<p><code class="docutils literal notranslate"><span class="pre">opsset</span></code>
Set of OpsSet options supported by the target device (experimental). Choose from</p>
<ol class="arabic simple">
<li><p><cite>tflite</cite>, which refers to <cite>[tensorflow.lite.OpsSet.TFLITE_BUILTINS]</cite></p></li>
<li><p><cite>tf</cite>, which refers to <cite>[tensorflow.lite.OpsSet.SELECT_TF_OPS, tensorflow.lite.OpsSet.TFLITE_BUILTINS]</cite></p></li>
<li><p><cite>int8</cite>, which refers to <cite>[tensorflow.lite.OpsSet.TFLITE_BUILTINS_INT8]</cite></p></li>
</ol>
<p>Default is <cite>tflite</cite>.</p>
<p><code class="docutils literal notranslate"><span class="pre">load</span></code>
A python script that implements a data generation function that generates representative data for quantizing variable data, such as feature maps. The function should be named <cite>get_dataset</cite>, and it should be a generator function that yields large enough dataset to represent typical data values. Check <a class="reference external" href="https://github.com/LGE-ARC-AdvancedAI/auptimizer/tree/master/Examples/converter_examples/Convert_Benchmark/repdata.py">representative data</a> for example.</p>
<p><code class="docutils literal notranslate"><span class="pre">input_nodes</span></code>
Model input names (separated by comma), which can be found with <a class="reference external" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs">summarize graph tool</a>. Those names typically end with <cite>:0</cite>, for example <cite>input:0</cite>.</p>
<p><code class="docutils literal notranslate"><span class="pre">output_nodes</span></code>
Model output names (separated by comma). which can be found with <a class="reference external" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs">summarize graph tool</a>. Those names typically end with <cite>:0</cite>, for example <cite>output/Softmax:0</cite>.</p>
<p><code class="docutils literal notranslate"><span class="pre">input_shape</span></code>
If the <cite>input_nodes</cite> in <em>protobuf</em> or <em>checkpoint</em> has unspecified shapes other than the 1st dimension, the <cite>input_shape</cite> needs to be specified by a comma separated string, for example <cite>1,3,224,224</cite>. For multiple <cite>input_nodes</cite>, use <cite>;</cite> to separate their corresponding <cite>input_shape</cite>.
The shape of <cite>input_nodes</cite> can also be checked using the <a class="reference external" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs">summarize graph tool</a>, where unspecified shape is usually represented by <strong>-1</strong>.</p>
<p><code class="docutils literal notranslate"><span class="pre">network_script</span></code>
Path to a Python script that contains the model definition of the PyTorch model to be converted.</p>
<p><code class="docutils literal notranslate"><span class="pre">network_name</span></code>
Class name of the model to be converted, defined in the script specified in <cite>network_script</cite> .</p>
<p><code class="docutils literal notranslate"><span class="pre">onnx_opset</span></code>
Opset version to use for ONNX. Default is <cite>10</cite>. The ONNX opset version updates can be found in <a class="reference external" href="https://github.com/onnx/onnx/releases">ONNX release notes</a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">frozen</span></code>
Flag to control whether to create a frozen Protobuf. Default is <cite>True</cite>.</p>
<p><code class="docutils literal notranslate"><span class="pre">savedmodel_tag</span></code>
Tag to use for SavedModel. Default is <cite>serve</cite>. The SavedModel to be converted <em>cannot have an emtpy tag</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">savedmodel_signature</span></code>
Signature to use for SavedModel within the specified <cite>–tag</cite> value. Default is <cite>serving_default</cite>. The SavedModel to be converted <em>cannot have an emtpy signature</em>.</p>
<p><code class="docutils literal notranslate"><span class="pre">skip</span></code>
This parameter is for converting selected models when there are multiple conversion configurations in the json file. When set to <cite>True</cite>, the model will be skipped and not be converted. Default is <cite>False</cite>.</p>
</div>
<div class="section" id="known-issues">
<h2>Known Issues<a class="headerlink" href="#known-issues" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Limited support on certain model architectures</p></li>
<li><p>Quantization for TensorFlow Lite conversion can lead to <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues/40000">significant accuracy loss</a></p></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dlconvert_example.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="dlconvert.html" class="btn btn-neutral float-left" title="Converter" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018, LG Electronics Inc.

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>